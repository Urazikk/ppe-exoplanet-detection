import pandas as pd
import numpy as np
import xgboost as xgb
import json
import os
import sys
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix
from sklearn.feature_selection import SelectFromModel

# Configuration du PATH pour les imports
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

def train_exoplanet_model():
    """
    EntraÃ®ne l'IA sur le dataset d'entraÃ®nement et valide sur le set de test indÃ©pendant.
    OptimisÃ© pour gÃ©rer le dÃ©sÃ©quilibre des classes.
    """
    train_path = "data/processed/training_dataset.csv"
    test_path = "data/processed/test_dataset.csv"
    model_dir = "models"
    
    if not os.path.exists(train_path) or not os.path.exists(test_path):
        print("âŒ Erreur : Les datasets CSV sont introuvables. Relancez le gÃ©nÃ©rateur.")
        return

    print("ðŸš€ Chargement des donnÃ©es CSV...")
    df_train = pd.read_csv(train_path)
    df_test = pd.read_csv(test_path)
    
    # 1. PrÃ©paration robuste des donnÃ©es
    y_train = df_train['target_label']
    y_test = df_test['target_label']

    # Filtrage des colonnes numÃ©riques uniquement
    X_train = df_train.select_dtypes(include=[np.number]).drop(columns=['target_label'], errors='ignore').fillna(0)
    X_test = df_test.select_dtypes(include=[np.number]).drop(columns=['target_label'], errors='ignore').fillna(0)
    
    # Affichage de la rÃ©partition pour diagnostic
    print(f"ðŸ“Š EntraÃ®nement : {len(y_train)} Ã©chantillons ({sum(y_train==1)} PlanÃ¨tes / {sum(y_train==0)} Bruit)")
    print(f"ðŸ“Š Test : {len(y_test)} Ã©chantillons ({sum(y_test==1)} PlanÃ¨tes / {sum(y_test==0)} Bruit)")

    if sum(y_train==0) == 0:
        print("âš ï¸ ALERTE : Aucun Ã©chantillon de bruit (classe 0) dans l'entraÃ®nement. L'IA ne peut pas apprendre Ã  comparer.")

    # 2. SÃ©lection des caractÃ©ristiques (Feature Selection)
    print("ðŸ” SÃ©lection des caractÃ©ristiques pertinentes...")
    selector_clf = xgb.XGBClassifier(n_estimators=100, max_depth=3, random_state=42)
    selector_clf.fit(X_train, y_train)
    
    # On augmente le seuil pour ne garder que le top des caractÃ©ristiques
    selection = SelectFromModel(selector_clf, threshold="1.25*median", prefit=True)
    selected_features = X_train.columns[selection.get_support()].tolist()
    
    X_train_v2 = selection.transform(X_train)
    X_test_v2 = selection.transform(X_test)
    
    print(f"âœ¨ {len(selected_features)} caractÃ©ristiques critiques conservÃ©es.")

    # 3. Apprentissage du ModÃ¨le Final
    print("ðŸ§  EntraÃ®nement du modÃ¨le XGBoost final...")
    
    # Calcul dynamique du poids (Balance)
    n_neg = len(y_train[y_train == 0])
    n_pos = len(y_train[y_train == 1])
    # On donne beaucoup plus de poids Ã  la classe minoritaire (le bruit) pour forcer l'IA Ã  y faire attention
    weight = n_neg / n_pos if n_pos > 0 else 1

    model = xgb.XGBClassifier(
        n_estimators=500,        # Plus d'arbres pour capter les nuances
        learning_rate=0.03,      # Apprentissage plus lent
        max_depth=4,             # Moins profond pour Ã©viter de "mÃ©moriser" (Overfitting)
        scale_pos_weight=weight,
        eval_metric='logloss',
        random_state=42
    )
    
    model.fit(X_train_v2, y_train)

    # 4. Ã‰valuation sur le Test Set
    print("\nðŸ“ˆ RÃ‰SULTATS SUR LE TEST SET :")
    y_pred = model.predict(X_test_v2)
    acc = accuracy_score(y_test, y_pred)
    
    print(f"PrÃ©cision globale (Accuracy) : {acc:.2%}")
    print("\nMatrice de Confusion :")
    # Rappel : [ [Vrais NÃ©gatifs, Faux Positifs], [Faux NÃ©gatifs, Vrais Positifs] ]
    print(confusion_matrix(y_test, y_pred))
    print("\nRapport de Classification :")
    print(classification_report(y_test, y_pred, zero_division=0))

    # 5. Sauvegardes
    os.makedirs(model_dir, exist_ok=True)
    model.save_model(f"{model_dir}/exoplanet_model.json")
    
    with open(f"{model_dir}/selected_features.json", "w") as f:
        json.dump(selected_features, f)
        
    print(f"\nâœ… IA sauvegardÃ©e dans /{model_dir}")

if __name__ == "__main__":
    train_exoplanet_model()